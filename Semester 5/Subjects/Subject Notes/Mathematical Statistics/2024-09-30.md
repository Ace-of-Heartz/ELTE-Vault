---
is_lecture: true
course: "[[Matematikai statisztika Ea + Gy]]"
---
# Becsléselmélet
**Cél:** minta eloszlásának ismeretlen paraméterének közelítése a minta függvényével
## Def.: Becslőfüggvény
$\hat{\vartheta}:\chi \to \Theta$, ahol $\Theta$ a paraméterhalmaz 
## Def.: Becslés 
$\hat{\vartheta}(\xi)$, ahol $\xi$ valószínűségi vektorváltozó 

*Becslések* is statisztikák!
**Szubjektíven**: olyan statisztikák, amik jól közelítik a fenti ismeretlen paramétert 

# Likelihood függvény
## Def.: 
**Legyen**: $\xi_{1}, \xi_{2},\dots,\xi_{n}$ *független, azonos eloszlású minta*
**Ekkor**: ennek a mintának a *likelihood* függvénye:
$$
L(x,\theta) = \begin{cases}
P_{\theta}(\xi=x) = \prod^n_{i=1} P_{\theta}(\xi_{i} = x_{i}),\ diszkrét\ minta\ esetén \\
f_{\theta}(x) = \prod^n_{i=1} f_{\theta}(x_{i}),\ abszolút\ folytonos\ minta\ esetén
\end{cases}
$$
Itt $f_{\theta}\ \xi_{i}$ sűrűségfv.-e

**Spec.:** $l(x,\theta)$ = $ln(L(x,\theta))$ a loglikelihood fv.

## Maximum Likelihood Becslés
### Def.: (heurisztikusan)
**Cél**: azon paraméterérték keresése, amelyre az adott minta bekövetkezési valószínűsége maximális
**Def.:** $\theta$ *maximum likelihood becslése* $\hat{\theta} = T(\xi) \in \Theta$, **ha**: $L(\xi,\hat{\theta}) = \max_{\theta \in \Theta}L(\xi,\theta)$  

**Ált.:** loglikelihood függvény maximumhelyének keresése $\frac{\partial l(x,\theta)}{\partial \theta}$ = 0 egyenletet (vagy rendszert) megoldva

Példák:
- *Poisson*
- *Indikátor*
## Likelihood egyenlet


# Becslések tulajd.:
## Def.: *Torzítatlanság*
Paraméter $\hat{\vartheta}(\xi)$ becslése *torzítatlan*, ha $E_{\vartheta}(\hat{\vartheta}(\xi)) = \vartheta , \ \forall \vartheta \in \Theta$ (azaz a várható értéke (?) megegyezik)

## Def.: *Konzisztencia* 
$\hat{\vartheta}(\xi) \to \vartheta$ sztochasztikusan (konvergál) ($n \to \infty$) minden paraméterértékre
**Elégséges felt.:**
- $E_{\vartheta}(\hat{\vartheta}(\xi)) \to \vartheta$ (aszimptotikus torzítatlanság)
- ÉS $D_{\vartheta}^2(\hat{\vartheta}(\xi)) \to 0$

Példák:
- Valószínűség becslése relatív gyakorisággal
- Várható érték becslése mintaátlaggal
### Glivenko tétele: 
- Tapasztalati eloszl. fv. *egyenletesen is konvergál* az elméleti eloszlásfüggvényhez
## Példák:
- Poisson eloszlás paraméterére: *mintaátlag*
- Exponenciális eloszlás paraméterére: 
	- *mintaátlag reciproka*: aszimptotikusan torzítatlan, konzisztens
	- $n *min(X_{1},\dots,X_{n})$ 
- Szórásnégyzetre

## Becslések összehasonlítása
Torzítatlan becslésekre:
- $T_1$ hatásosabb becslése $h(\Theta)$-nak a $T_2$-nél, ha szórásnégyzete $T_1$-nek kisebb mint $T_2$-nek 
- teljesül minden $\Theta$ paraméterértékre

## Def.: *Hatásos becslése
$T$ torzítatlan becslés hatásos*, ha minden más torzítatlan becslésnél *hatásosabb*
**Átlagos négyzetes eltérés**: $E_{\theta}(T(\underline{X})-\theta)^2$

## Áll.: *Hatásos becslés egyértelműsége*
**Amennyiben**: $T_1$ és $T_2$ hatásos becslései h($\theta$)-nak
**akkor**: 1 valószínűséggel megegyeznek minden lehetséges paraméter esetén

![[Pasted image 20241004210906.png]]
## Elégséges statisztika
- Minden információt (ugyanannyit mint az eredeti minta) tartalmaz az ismeretlen paraméterre vonatkozóan
- "Elég" az ő értékét ismerni
- Ismeretében már "nincs bizonytalanság" a mintában (egyértelmű a minta eloszlása, nem függ az ismeretlen paramétertől)

### Def.: *Diszkrét minta esetén*
Diszkrét $\xi$ mintából képzett $T(\xi)$ statisztika elégséges $\theta$-ra, ha $P_{\theta}(\xi=x|T(\xi) = t)$ feltételes valószínűség *nem függ* $\theta$-tól

## Feltételes várható érték 
**Legyenek**: X és Y *diszkrét* val. változók 
**Ekkor**: E(X|Y) az a *val. változó*, ami az Y = $y_k$ eseményen az $E(X|Y = y_{k})$ értéket veszi fel

**Tulajd**: 
- Ha $X \geq 0$ ==> $E(X|Y) \geq 0$ 
- $E(E(X|Y)) = EX$ - a teljes várható érték tételének általánosítása 
- Ha $X_1,\  X_2$ várható érték véges ==> $E(c_{1}X_{1} + c_{2}X_{2}|Y) = c_{1}E(X_{1}|Y) + c_{2}E(X_{2}|Y)$
- Ha X függelten Y-tól ==> $E(X|Y) = E(X)$ 
- Ha X és h(Y) várható értéke véges ==> $E(h(Y)X|Y) = h(Y)E(X|Y)$ 
- **Teljes szórásnégyzet tétele**: $D^2(X) = D^2(E(X|Y)) + E(D^2(X|Y))$ 

## Tétel: *Neyman-féle faktorizációs*
## Def.: *Elégséges statisztika általában*

## Def.: *Abszolút folytonos eset* 

## Maximum likelihood becslés
- Mindig az *elégséges statisztika függvénye*
- $E(0,a)$ minta esetén a ML becslése $max_{1\leq i \leq n}\xi_{i}$ 

## Momentum módszer 
**Ha**: az eloszlást k db paraméter határozza meg
**Akkor**: k db egyenletből kaphatunk rájuk becslést 

Az egyenletek a tapasztalati és az elméleti momentumok egybevetéséből adódnak: 
$$m_{i} (\underline{\theta}) = E_{\underline{\theta}}(X^i)$$
$$m_{i} (\underline{\theta}) =  \frac{\sum^n_{j=1}(\xi_{j})^i}{n}$$

